{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial Eight (Python): LSTMs and Bi-LSTMs ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucZj9e2JucZr"
      },
      "source": [
        "# Classification with LSTMs and Bi-LSTMS\n",
        "\n",
        "## Douglas Rice\n",
        "\n",
        "*This tutorial was originally created by Burt Monroe for his prior work with the Essex Summer School. I've updated and modified it.*\n",
        "\n",
        "In this notebook, we'll move beyond the simple feed-forward architectures we have set up in prior neural networks to setting up neural networks that are explicitly trying to learn about *sequences*. We'll look specifically at **L**ong **S**hort-**T**erm **M**emory (LSTM) and **bi**directional  (bi-LSTM)  networks. In terms of building the models in Keras, the modifications will be relatively straightforward updates. Computationally, however, we are adding significant complexity, and the additional complexity means the models will take longer to estimate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCs4681FucZs"
      },
      "source": [
        "## Set Everything Up"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As always, we start by getting our environment, loading in the modules and functionality that we'll need to estimate the model."
      ],
      "metadata": {
        "id": "nELx1ItFes8B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9v3e9tRucZs"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import models\n",
        "\n",
        "max_features = 5000\n",
        "maxlen = None  # This will pad shorter reviews to the length of the longest review. Set maxlen=200 or 500 for less padding at the expense of truncating the reviews.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwWl9aPEucZt"
      },
      "source": [
        "## Load the IMDB movie review sentiment data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll stick with the IMDB movie review sentiment data that ships with Keras for this exercise. One benefit is that we can maintain pretty direct comparisons across all of these different modeling approaches."
      ],
      "metadata": {
        "id": "Vzb7rQnxe6ZT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dhoU-3MvLSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77f2d38-7d31-48ea-f098-0ff02fc04b8e"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(\n",
        "    num_words=max_features\n",
        ")\n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_test), \"Test sequences\")\n",
        "partial_x_train = keras.preprocessing.sequence.pad_sequences(partial_x_train, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "25000 Training sequences\n",
            "25000 Test sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4NGMddsucZt"
      },
      "source": [
        "## Build a basic LSTM model\n",
        "\n",
        "Building a basic LSTM is very simple in Keras. We just add an LSTM layer in our Sequential model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXXSKCeQZPcL",
        "outputId": "ec841e1a-8f84-4832-b134-c9c9b731de03"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Input(shape=(None,), dtype=\"int32\"))\n",
        "model.add(layers.Embedding(max_features,16))\n",
        "model.add(layers.LSTM(16))\n",
        "model.add(layers.Dense(1, activation= 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 16)          80000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 16)                2112      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,129\n",
            "Trainable params: 82,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiPPmdL6ucZu"
      },
      "source": [
        "## Train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OegHDyQGwG7n"
      },
      "source": [
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeDnMihFxb1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0822e53b-ad9a-4132-8565-a110fa7a1bbc"
      },
      "source": [
        "model.fit(partial_x_train, partial_y_train, batch_size=512, epochs=12, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "30/30 [==============================] - 11s 125ms/step - loss: 0.6901 - accuracy: 0.5767 - val_loss: 0.6832 - val_accuracy: 0.6410\n",
            "Epoch 2/12\n",
            "30/30 [==============================] - 3s 108ms/step - loss: 0.6211 - accuracy: 0.7179 - val_loss: 0.9895 - val_accuracy: 0.4947\n",
            "Epoch 3/12\n",
            "30/30 [==============================] - 3s 109ms/step - loss: 0.6686 - accuracy: 0.6993 - val_loss: 0.6003 - val_accuracy: 0.7815\n",
            "Epoch 4/12\n",
            "30/30 [==============================] - 3s 110ms/step - loss: 0.5378 - accuracy: 0.8105 - val_loss: 0.5075 - val_accuracy: 0.7746\n",
            "Epoch 5/12\n",
            "30/30 [==============================] - 4s 139ms/step - loss: 0.4505 - accuracy: 0.8316 - val_loss: 0.4388 - val_accuracy: 0.8468\n",
            "Epoch 6/12\n",
            "30/30 [==============================] - 3s 108ms/step - loss: 0.3913 - accuracy: 0.8627 - val_loss: 0.4014 - val_accuracy: 0.8538\n",
            "Epoch 7/12\n",
            "30/30 [==============================] - 3s 108ms/step - loss: 0.3508 - accuracy: 0.8796 - val_loss: 0.3782 - val_accuracy: 0.8498\n",
            "Epoch 8/12\n",
            "30/30 [==============================] - 3s 109ms/step - loss: 0.3102 - accuracy: 0.8890 - val_loss: 0.3596 - val_accuracy: 0.8524\n",
            "Epoch 9/12\n",
            "30/30 [==============================] - 3s 109ms/step - loss: 0.2739 - accuracy: 0.9064 - val_loss: 0.3376 - val_accuracy: 0.8637\n",
            "Epoch 10/12\n",
            "30/30 [==============================] - 3s 108ms/step - loss: 0.2429 - accuracy: 0.9195 - val_loss: 0.3349 - val_accuracy: 0.8637\n",
            "Epoch 11/12\n",
            "30/30 [==============================] - 3s 110ms/step - loss: 0.2213 - accuracy: 0.9280 - val_loss: 0.3313 - val_accuracy: 0.8659\n",
            "Epoch 12/12\n",
            "30/30 [==============================] - 3s 110ms/step - loss: 0.2064 - accuracy: 0.9338 - val_loss: 0.3249 - val_accuracy: 0.8704\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f606f3ec410>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsiUYVUGiF7_",
        "outputId": "baa67987-3251-4796-9b0f-3de4a4e44556"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 24s 31ms/step - loss: 0.3397 - accuracy: 0.8617\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33969274163246155, 0.8617200255393982]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vBd1d9AiKXX"
      },
      "source": [
        "86%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6uDEGW7is8o"
      },
      "source": [
        "## Build a basic bi-LSTM model\n",
        "\n",
        "Let's see if a bidirectional LSTM does any better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgUN6Ckeis80",
        "outputId": "50eeb90d-b8ca-4022-dc44-4300b4cd8bbd"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Input(shape=(None,), dtype=\"int32\"))\n",
        "model.add(layers.Embedding(max_features,16))\n",
        "model.add(layers.Bidirectional(layers.LSTM(16)))\n",
        "model.add(layers.Dense(1, activation= 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 16)          80000     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 32)               4224      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,257\n",
            "Trainable params: 84,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQZ1SbjBis80"
      },
      "source": [
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCvCRKLIis81",
        "outputId": "719c05b1-0668-47e3-9692-9e16d76afafc"
      },
      "source": [
        "model.fit(partial_x_train, partial_y_train, batch_size=512, epochs=12, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "30/30 [==============================] - 10s 236ms/step - loss: 0.6902 - accuracy: 0.5570 - val_loss: 0.6838 - val_accuracy: 0.6589\n",
            "Epoch 2/12\n",
            "30/30 [==============================] - 6s 206ms/step - loss: 0.6279 - accuracy: 0.7217 - val_loss: 0.9273 - val_accuracy: 0.5109\n",
            "Epoch 3/12\n",
            "30/30 [==============================] - 6s 206ms/step - loss: 0.5858 - accuracy: 0.7383 - val_loss: 0.5141 - val_accuracy: 0.7943\n",
            "Epoch 4/12\n",
            "30/30 [==============================] - 6s 208ms/step - loss: 0.4426 - accuracy: 0.8345 - val_loss: 0.4670 - val_accuracy: 0.7804\n",
            "Epoch 5/12\n",
            "30/30 [==============================] - 6s 208ms/step - loss: 0.4157 - accuracy: 0.8291 - val_loss: 0.4075 - val_accuracy: 0.8355\n",
            "Epoch 6/12\n",
            "30/30 [==============================] - 6s 209ms/step - loss: 0.3487 - accuracy: 0.8729 - val_loss: 0.3864 - val_accuracy: 0.8407\n",
            "Epoch 7/12\n",
            "30/30 [==============================] - 7s 225ms/step - loss: 0.3120 - accuracy: 0.8893 - val_loss: 0.3797 - val_accuracy: 0.8429\n",
            "Epoch 8/12\n",
            "30/30 [==============================] - 6s 208ms/step - loss: 0.2958 - accuracy: 0.8934 - val_loss: 0.3801 - val_accuracy: 0.8386\n",
            "Epoch 9/12\n",
            "30/30 [==============================] - 6s 209ms/step - loss: 0.2820 - accuracy: 0.8981 - val_loss: 0.4268 - val_accuracy: 0.8157\n",
            "Epoch 10/12\n",
            "30/30 [==============================] - 6s 209ms/step - loss: 0.2667 - accuracy: 0.9051 - val_loss: 0.3529 - val_accuracy: 0.8523\n",
            "Epoch 11/12\n",
            "30/30 [==============================] - 6s 206ms/step - loss: 0.2380 - accuracy: 0.9189 - val_loss: 0.3690 - val_accuracy: 0.8468\n",
            "Epoch 12/12\n",
            "30/30 [==============================] - 6s 207ms/step - loss: 0.2256 - accuracy: 0.9243 - val_loss: 0.3512 - val_accuracy: 0.8571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f607c016c90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoA-rFxbis81",
        "outputId": "f96cfb1a-f3a1-4995-d532-64d415541a7d"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 47s 59ms/step - loss: 0.3619 - accuracy: 0.8526\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3619060814380646, 0.8525999784469604]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYKcrRBGjlzL"
      },
      "source": [
        "\n",
        "85%. Going in the wrong direction!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uk1aKWAjy-m"
      },
      "source": [
        "## Build a more expressive, deeper bi-LSTM model with dropout.\n",
        "\n",
        "Bi-LSTMs seem to gain power when stacked in multiple layers. Let's do that, make everything bigger, and add some regularization through dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxX635zxjy-m"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Input(shape=(None,), dtype=\"int32\"))\n",
        "model.add(layers.Embedding(max_features,64))\n",
        "model.add(layers.Dropout(.3))\n",
        "model.add(layers.Bidirectional(layers.LSTM(32, return_sequences=True))) # return_sequences is necessary when stackin LSTMs\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(layers.Bidirectional(layers.LSTM(16)))\n",
        "model.add(layers.Dense(1, activation= 'sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVfZndfpjy-n"
      },
      "source": [
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeM2jpmNjy-n",
        "outputId": "1268f050-8e32-4925-8b09-0196f8c1d0fc"
      },
      "source": [
        "model.fit(partial_x_train, partial_y_train, batch_size=512, epochs=3, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "30/30 [==============================] - 25s 683ms/step - loss: 0.6821 - accuracy: 0.6114 - val_loss: 0.6115 - val_accuracy: 0.7387\n",
            "Epoch 2/3\n",
            "30/30 [==============================] - 19s 630ms/step - loss: 0.4915 - accuracy: 0.7846 - val_loss: 0.4092 - val_accuracy: 0.8336\n",
            "Epoch 3/3\n",
            "30/30 [==============================] - 19s 623ms/step - loss: 0.3331 - accuracy: 0.8742 - val_loss: 0.3724 - val_accuracy: 0.8501\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6077c4a4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0yvWfgcjy-n",
        "outputId": "6c526f16-d29b-45bd-f3cf-b3e1c8ee2895"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 90s 113ms/step - loss: 0.3764 - accuracy: 0.8517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3764491677284241, 0.8516799807548523]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RYxaOVKjy-n"
      },
      "source": [
        "85%.\n",
        "\n",
        "It's worth noting, perhaps, that the even bigger, even more expressive model in the Keras documentation (128-dimensional embedding layer, and TWO 64-node BiLSTM layers -- 2.8 million parameters) gets accuracy in the test set of 86.8%. (https://keras.io/examples/nlp/bidirectional_lstm_imdb/)\n",
        "\n",
        "And we did a bit better, 88%, with our basic feedforward network with some dropout."
      ]
    }
  ]
}